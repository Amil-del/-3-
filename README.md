1) Сортировка выбором
Этот цикл выполняется от первого элемента до предпоследнего (n - 1 шагов), где n - длина массива. Следовательно, количество итераций внешнего цикла составляет O(n). Внутри внешнего цикла идет проверка всех остальных элементов справа от текущего. Так как внутренний цикл начинается с (i + 1) и заканчивается последним элементов, число проверок уменьшается с каждой итерацией внешнего цикла: 1) Первая итерация внешнего цикла выполнит проверку n - 1 раз, 2) Вторая итерация выполнит проверку n - 2 раз, 3) Третья итерация - (n - 3), и так далее. Общее количество сравнений внутреннего цикла равно сумме первых (n - 1) целых чисел, что выражается формулой арифметической прогрессии:
S = (n-1) + (n-2) + ... + 1 = (n-1)*n/2
Замены выполняются ровно столько же раз, сколько внешний цикл прошел полных итераций, то есть примерно 
n раз. Однако поскольку этот процесс занимает константное время, общая асимптотическая оценка остается квадратичной. Поскольку доминирующим фактором является внутренний цикл, итоговая временная сложность алгоритма сортировки выбором равна:
O(n^2) 
Таким образом, алгоритм имеет временную сложность порядка квадрата размера массива, независимо от начальных условий (упорядоченности или хаоса в данных).
2)Сортировка обменом
Основной цикл (внешний) выполняется n раз, где n — длина списка. Внутренний цикл также проходит почти всю длину списка на каждой итерации внешнего цикла. Количество внутренних итераций на первой полной итерации составит около n, затем на следующей итерации оно уменьшится на единицу и так далее. Полное количество сравнений представляет собой сумму последовательности вида: 
(n - 1) + (n - 2) + (n - 3) + … + 1. Это арифметическая прогрессия, сумма которой приблизительно равна n(n-1)/2, что эквивалентно порядку роста O(n^2). Каждая замена производится за постоянное время, следовательно, операции присвоения также учитываются в общей оценке сложности, однако они остаются частью внутренней структуры и не меняют общую оценку. Хотя в представленном примере предусмотрена оптимизация досрочного прекращения, когда массив уже отсортирован, такая ситуация возникает редко и не влияет существенно на среднюю и худшую оценки. Исходя из вышеперечисленных факторов, средняя и худшая временные сложности алгоритма Bubble Sort составляют: O(n^2). Это означает, что при увеличении количества элементов в списке скорость выполнения алгоритма значительно замедляется пропорционально квадрату размера входных данных.
3) Сортировка вставками
Внешний цикл проходит по каждому элементу массива кроме первого (O(n)). Для примера возьмем массив длиной n. Внутренний цикл проверяет каждый элемент слева от текущего ключа, пока не выйдет подходящее место для вставки (O(k), где k - число шагов внутреннего цикла). Этот внутренний цикл может выполняться максимум i раз (от начала массива до текущей позиции i), поскольку каждая итерация внешнего цикла увеличивает длину отсортированного участка. Таким образом, в худшем случае (массив отсортирован в обратном порядке) внутренняя проверка должна пройти практически всю длину массива, создавая вложенную структуру циклов: Внешний цикл: O(n), Внутренний цикл: O(i) примерно равно O(n). Это означает, что общее количество операций пропорционально квадрату длины массива: 
T(n) = O(n^2)
Поэтому итоговая временная сложность алгоритма сортировки вставками равна O(n^2) в худшем и среднем случаях. Однако в лучшем случае (если массив уже отсортирован), временная сложность снижается до O(n), так как внутренние проверки завершаются быстро.
4) Сортировка слиянием
Каждое разделение требует примерно log2(n) шагов, поскольку каждый раз размер обрабатываемых участков уменьшается вдвое. Для каждого уровня разделения производится операция объединения, которая проход по каждому элементу массива ровно один раз. Следовательно, на каждом уровне слияния сложность равна O(n). Таким образом, общее количество операций складывается из количества уровней (двоичный логарифм числа элементов) умноженного на операции на каждом уровне (n). BIG-O(T(n)) = O(log2(n)) * O(n) = O(n*log(n)). Итоговая временная сложность алгоритма сортировки слиянием: O(n*log(n)).
5) Сортировка Шелла
Сначала выбирается начальная величина интервала h, которая уменьшается на каждой итерации. Обычно выбирают специальную последовательность значений интервала, такую как последовательность Марсенна (например, 1,4,13,40,…) или другую оптимизированную последовательность. Внешний цикл уменьшает интервал 
h на каждой итерации. Внутри внешнего цикла внутренний цикл производит вставочную сортировку с шагом h. То есть, сравниваются и переставляются элементы, расположенные на расстоянии h друг от друга. Каждый внутренний цикл требует порядка O(n) сравнений и перемещений (так как перебираются почти все элементы массива). Количество проходов внешним циклом зависит от выбранного метода выбора величины интервала. Например, если используются степени двойки или последовательность Марсенна, число проходов будет примерно пропорционально логарифму длины массива N. На каждом этапе внутреннего цикла совершается вставочная сортировка с расстоянием h, что дает дополнительную сложность порядка O(n). Следовательно, общая временная сложность алгоритма Шелла сильно зависит от используемого правила уменьшения интервала. Для большинства стандартных последовательностей интервалов средняя временная сложность приближенно оценивается как: O(N^(3/2)). Однако существует улучшенные последовательности интервалов, которые позволяют приблизить временную сложность к: 
O(N*log^2(N)) или даже лучше, до: 
O(N*log(N)).
Но стандартный вариант, использованный в приведённым примере, обеспечивает среднюю оценку порядка O(N^(3/2)), хотя точные оценки зависят от деталей реализации и последовательности интервалов.
6) Быстрая сортировка
Если массив содержит 0 или 1 элемент, он уже отсортирован, и работа занимает константное время. Выбор центрального элемента массива занимает постоянное время. Создание трёх списков (элементов меньше, равных и больших опорного) требует прохода по всему массиву размером n. Быстрая сортировка рекурсивно применяется к двум частям массива. Лучший случай: Если массив идеально разделяется на две приблизительно равные части на каждом шаге, глубина рекурсии составит log(n), а на каждом уровне потребуется линейное время O(n). Итого получаем:
O(n*log(n)). Средний случай: В большинстве случаев алгоритм ведет себя аналогично лучшему случаю, обеспечивая среднее время:
O(n*log(n)). Однако возникает худший случай, если массив уже отсортирован или почти отсортирован, и каждый раз выбирается минимальный/максимальный элемент в качестве опорного. Тогда на каждом шаге одна из частей становится пустой, а другая содержит n - 1 элементов. Глубина рекурсии достигает n, и каждое действие требует линейного времени O(n). Итого получается квадратичное время: 
O(n^2).
7) Пирамидальная сортировка
Процесс построения max-кучи выполняется с использованием функции heapify. Для каждого внутреннего узла дерева выполняется операция heapify, которая требует O(log(n)) операций, где n - количество элементов в дереве. Поскольку мы выполняем операцию heapify примерно для половины узлов (родителей), общее количество операций для построения кучи составляет порядка O(n). Каждый раз, когда мы извлекаем максимальный элемент из кучи, нам снова нужно восстановить свойства кучи с помощью операций heapify. Операция извлечения выполняется n раз, и каждая операция heapify занимает O(log(n)) времени. Таким образом, общая сложность этапа извлечения равна O(n*log(n)). Общая временная сложность алгоритма складывается из двух основных этапов:
O(n) + O(n*log(n)) = O(n*log(n))
Здесь доминирующим фактором является второй этап (O(n*log(n))), поскольку он растет быстрее, чем линейный этап (O(n)). 
Алгоритм пирамидальной сортировки имеет временную сложность O(n*log(n)) в худшем, среднем и лучшем случаях. Этот алгоритм эффективен для сортировки больших массивов данных благодаря своей стабильной производительности независимо от начального от начального порядка элементов.
8) Последовательный список
Алгоритм последовательно просматривает каждый элемент списка, пока не найдет целевой элемент или не достигнет конца списка. Количество итераций зависит от размера списка n. Каждая проверка условия (arr[index] == target) представляет собой константную операцию, требующую фиксированное время вне зависимости от размера данных. В худшем случае цель не обнаруживается в списке либо находится в последнем элементе. Тогда алгоритм выполнит проверку ровно n раз, где n - длина списка. Лучшим случаем является ситуация, когда целевой элемент расположен в первой позиции списка. Однако это не влияет на общую оценку сложности, так как анализируется поведение алгоритма в худших условиях. Среднее число проверок близко к половине длины списка, однако среднее также оценивается как O(n). Линейная зависимость сохраняется ввиду того, что нельзя заранее предсказать позицию цели. Исходя из анализа, алгоритм гарантированно потребует просмотреть весь список целиком в худшем сценарии. Таким образом, временная сложность алгоритма линейного поиска равна O(n), где n - длина исходного списка.
9) Бинарный поиск
В каждом шаге цикла область поиска делится пополам. Например, если изначально имеется список длиной n,  то после первой итерации останется половина списка (n/2), после следующей - (n/4), и так далее. Поскольку на каждой итерации размер исследуемой области сокращается вдвое, максимальное количество итераций равно количеству раз, которое нужно поделить n на 2, чтобы достичь единица. То есть количество итераций приблизительно равняется log2(n). В наилучшем случае (если искомый элемент находится в середине на первом же шаге), алгоритм вернёт результат мгновенно, и сложность составит O(1). Но такая ситуация маловерятна и не учитывается при оценке общей эффективности. Бинарный поиск всегда работает за время O(log(n)) незавасимо от расположения искомого элемента в списке. Даже в худшем случае (когда эллемент находится в крайних позициях или вовсе отсутствует) количество сравнений ограничено величиной log2(n). Учитывая изложенное, средняя и худшая временная сложность алгоритма бинарного поиска равна O(log(n)), где n - длина отсортированного списка.
10) Алгоритм интерполирующего поиска отличается своей временной сложностью от классического бинарного поиска благодаря методу расчета промежуточной точки, основанному на предположениях о равномерности распределения элементов. O(log(log(N))), если элементы массива действительно равномерно распределены. Это значительно лучше бинарного поиска O(log(N)). Теоретически возможен O(N), если распределение крайне неравномерное либо если шаги оказываются неудачными (например, если элементы расположены хаотично). Тем не менее, такая ситуация встречается редко. Таким образом, средняя и лучшая временные сложности алгоритма существенно превосходят классические методы поиска в упорядоченных структурах, однако худший случай приближается к обычному последовательному поиску. Поэтому важно учитывать специфику конкретного набора данных перед использованием интерполирующего поиска. 
